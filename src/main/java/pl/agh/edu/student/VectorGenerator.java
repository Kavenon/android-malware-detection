package pl.agh.edu.student;

import org.deeplearning4j.models.paragraphvectors.ParagraphVectors;
import org.deeplearning4j.models.word2vec.VocabWord;
import org.deeplearning4j.models.word2vec.wordstore.inmemory.AbstractCache;
import org.deeplearning4j.text.documentiterator.LabelsSource;
import org.deeplearning4j.text.sentenceiterator.CollectionSentenceIterator;
import org.deeplearning4j.text.sentenceiterator.SentenceIterator;
import org.deeplearning4j.text.tokenization.tokenizer.preprocessor.CommonPreprocessor;
import org.deeplearning4j.text.tokenization.tokenizerfactory.DefaultTokenizerFactory;
import org.deeplearning4j.text.tokenization.tokenizerfactory.TokenizerFactory;

import java.util.Arrays;
import java.util.List;

public class VectorGenerator {
    public ParagraphVectors generate(List<String> labels, List<String> texts, ParagraphVectors.Builder builder, AbstractCache<VocabWord> cache){
        SentenceIterator iter = new CollectionSentenceIterator(texts);

        LabelsSource source = new LabelsSource(labels);

        TokenizerFactory t =new DefaultTokenizerFactory();
        t.setTokenPreProcessor(new CommonPreprocessor());

        ParagraphVectors vec = builder
                .minWordFrequency(1)
                .iterations(5)
                .epochs(1)
                .layerSize(100)
                .learningRate(0.025)
                .labelsSource(source)
                .windowSize(5)
                .iterate(iter)
                .trainWordVectors(false)
                .vocabCache(cache)
                .labelsSource(source)
                .tokenizerFactory(t)
                .sampling(0)
                .build();

        vec.fit();

        return vec;
    }
}
